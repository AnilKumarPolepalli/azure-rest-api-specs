import "../messages/messages.tsp";

namespace Azure.AI.Projects;

/**
 * Represents advanced options for controlling agent runs.
 */
@doc("Represents advanced options for controlling agent runs.")
model RunOptions {
  /**
   * Strategy for truncating messages when input exceeds model limits.
   */
  @doc("Strategy for truncating messages when input exceeds model limits.")
  truncationStrategy?: TruncationStrategy;
}

/**
 * Describes how to truncate messages if they exceed model or provider limits.
 */
@doc("Describes how to truncate messages if they exceed model or provider limits.")
model TruncationStrategy {
  /**
   * The type of truncation strategy to apply.
   */
  @doc("The type of truncation strategy to apply.")
  type: "auto" | "lastMessages" | string;

  /**
   * The number of most recent messages to retain when using 'lastMessages' strategy.
   */
  @doc("The number of most recent messages to retain when using 'lastMessages' strategy.")
  lastMessages?: int32;
}

/**
 * Parameters for creating a new run request.
 */
@doc("Parameters for creating a new run request.")
model RunInputs {
  /**
   * The agent responsible for generating the run.
   */
  @doc("The agent responsible for generating the run.")
  agent: Agent;

  /**
   * The list of input messages for the run.
   */
  @doc("The list of input messages for the run.")
  input: ChatMessage[];

  /**
   * Optional identifier for an existing conversation thread.
   */
  @doc("Optional identifier for an existing conversation thread.")
  threadId?: string;

  /**
   * Optional metadata associated with the run request.
   */
  @doc("Optional metadata associated with the run request.")
  metadata?: Record<string>;

  /**
   * Optional configuration for run generation.
   */
  @doc("Optional configuration for run generation.")
  options?: RunOptions;

  /**
   * Identifier for the user making the request.
   */
  @doc("Identifier for the user making the request.")
  userId?: string;
}

/**
 * Detailed token usage data for a run request.
 */
@doc("Detailed token usage data for a run request.")
model CompletionUsage {
  /**
   * Number of run (completion) tokens used over the course of the run.
   */
  @doc("Number of run (completion) tokens used over the course of the run.")
  outputTokens: int64;

  /**
   * Number of prompt tokens used over the course of the run step.
   */
  @doc("Number of prompt tokens used over the course of the run step.")
  inputTokens: int64;

  /**
   * Total number of tokens used (prompt + run).
   */
  @doc("Total number of tokens used (prompt + run).")
  totalTokens: int64;

  /**
   * Details of the prompt tokens.
   */
  @doc("Details of the prompt tokens.")
  inputTokenDetails?: {
    /**
     * The number of cached prompt tokens.
     */
    @doc("The number of cached prompt tokens.")
    cachedTokens?: int32;
  };

  /**
   * Breakdown of tokens used in a run.
   */
  @doc("Breakdown of tokens used in a run.")
  outputTokenDetails?: {
    /**
     * Tokens generated by the model for reasoning.
     */
    @doc("Tokens generated by the model for reasoning.")
    reasoningTokens?: int32;
  };
}

/**
 * A streaming update indicating incremental changes to an agent-generated completion.
 */
@doc("A streaming update indicating incremental changes to an agent-generated completion.")
model StreamingAgentCompletionUpdate {
  /**
   * Identifier of the message being updated.
   */
  @doc("Identifier of the message being updated.")
  messageId: string;

  /**
   * Optional name of the message author.
   */
  @doc("Optional name of the message author.")
  authorName?: string;

  /**
   * Role of the author for the updated message.
   */
  @doc("Role of the author for the updated message.")
  authorRole?: AuthorRole;

  /**
   * Optional content updates from the AI.
   */
  @doc("Optional content updates from the AI.")
  update?: StreamingOperation;

  /**
   * Token usage information associated with this streaming update.
   */
  @doc("Token usage information associated with this streaming update.")
  usage: CompletionUsage;
}

/**
 * A sub-model containing the final output details, including status, messages, and usage.
 */
@doc("Fields describing the final run outcome, including status, output messages, and usage.")
model RunOutputs {
  /**
   * Final status of the run request.
   */
  @doc("Final status of the run request.")
  status:
    | "inProgress"
    | "incomplete"
    | "cancelled"
    | "failed"
    | "completed"
    | string;

  /**
   * List of output messages generated by the agent.
   */
  @doc("List of output messages generated by the agent.")
  output: ChatMessage[];

  /**
   * Token usage details for this run.
   */
  @doc("Token usage details for this run.")
  usage: CompletionUsage;

  /**
   * Details about why the response is incomplete, if applicable.
   */
  @doc("Details about why the response is incomplete, if applicable.")
  incompleteDetails?: {
    reason: string;
  };
}

/**
 * An agent-generated run record, composed via:
 *  - Top-level identity/timestamps
 *  - A composition with RunInputs (what was requested)
 *  - A composition with RunOutputs (the final outcome)
 */
@doc("An agent-generated run record, including both the requested inputs and the final outputs.")
@Rest.resource("runs")
model Run {
  /**
   * Unique identifier for the agent responsible for the run.
   */
  @doc("Unique identifier for the agent responsible for the run.")
  agentId: string;

  /**
   * Unique identifier for this run.
   */
  @key
  @visibility(Lifecycle.Read)
  @doc("Unique identifier for this run.")
  @visibility(Lifecycle.Read)
  runId: string;

  /**
   * Timestamp when the run was initiated (Unix time).
   */
  @doc("Timestamp when the run was initiated (Unix time).")
  createdAt: safeint;

  /**
   * Timestamp when the run finished processing (Unix time).
   */
  @doc("Timestamp when the run finished processing (Unix time).")
  completedAt: safeint;

  /**
   * The inputs used to create this run (e.g. which agent, which messages).
   * We embed them here so the final resource includes everything requested.
   */
  @doc("The inputs that were used to start this run.")
  runInputs: RunInputs;

  /**
   * The final outcome details: status, output messages, usage, etc.
   */
  @doc("The final outcome of this run, including status, output messages, token usage.")
  runOutputs: RunOutputs;

  /**
   * Optional configuration for run generation.
   */
  @doc("Optional configuration for run generation.")
  options?: RunOptions;

  /**
   * Identifier for the user making the request.
   */
  @doc("Identifier for the user making the request.")
  userId?: string;

  /**
   * Flag indicating whether to store the run and associated messages.
   */
  @doc("Flag indicating whether to store the run and associated messages.")
  store?: boolean;
}
