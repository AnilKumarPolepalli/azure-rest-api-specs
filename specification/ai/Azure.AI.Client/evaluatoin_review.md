## Concepts
### Evaluation
Evaluation is a run user creates by calling `/evaluations/create` API. It needs `data` and `evaluators` to execute at minimum. Once submitted user gets back an evaluation which has `id` propety set by service. Service also sets `status` property and value of it will change based on the state of run for example `Preparing, Completed` etc.


#### Create (/evaluation/create)

##### Request
```json
{
  "Data": {
    "Uri": "dataset_id"
  },
  "DisplayName": "Test",
  "Description": "Testing",
  "Evaluators": {
    "F1Score": {
        "Id": "evaluator_id"
        }
  }
}
```

#### Response
```json
{
  "Data": {
    "Uri": "dataset_id",
    "type": "dataset"
  },
  "DisplayName": "Test",
  "Description": "Testing",
  "Evaluators": {
    "F1Score": {
        "Id": "evaluator_id"
        }
  },
  "status": "Running", // Added by service 
  "id": "f418646d-1745-4606-acf5-f1b5dbd89097", // Added by service
  "tags" : {},
  "properties": {}
}
```

To get an evaluation user calls `evaluation/{id}` where `id` here is `evaluation id`

### Online Evaluation
Running evaluations on a schedule. This includes users creating a `schedule` which has `data`, `evaluators` and schedule details.

When user created online evaluatin, they create a schedule with information about what to run.

#### Create Online Evaluation (/evalutions/schedules/create)

#### Request
```json
{
  "Data": {
    "Uri": "dataset_id",
    "type": "app_insights",
    "resource_id": "<resourc_id>",
  },
  "Evaluators": {
    "F1Score": {
        "Id": "evaluator_id"
        }
  },
  "Recurrence": {
    "frequency": "Day",
    "interval": 1,
    "schedule": {
        "hours": "6",
    },
    "samplingStrategy": {
        "rate": 0.2
    }
  },
}
```

#### Response
```json
{
  "Data": {
    "Uri": "dataset_id",
    "type": "app_insights",
    "resource_id": "<resourc_id>",
  },
  "Evaluators": {
    "F1Score": {
        "Id": "evaluator_id"
        }
  },
  "Recurrence": {
    "frequency": "Day",
    "interval": 1,
    "schedule": {
        "hours": "6",
    },
    "samplingStrategy": {
        "rate": 0.2
    }
  },
  "id": "f418646d-1745-4606-acf5-f1b5dbd097", // Added by service
  "tags": {},
  "properties": {},
  "provisioningState" : "Creating"
}
```

To `get` a `schedule` user calls `evaluations/schedules/{id}` where `id` here is `schedule id`.

NOTE: There is no `status` field like `evaluation` and `id` is `schedule id`.

### Evaluation Results

Once evaluation completes it produces results, where it is one-off evaluation or an evaluation instance generated by scheduled evaluation.

#### Evaluation
Results are written to a `jsonl file` and is associated with the Evaluation.

No formal contract for now on where customer can find it as part of Evaluation get. Short term solution is to put the url to results file under properties. 

```json
{
  "Data": {
    "Uri": "dataset_id",
    "type": "dataset"
  },
  "DisplayName": "Test",
  "Description": "Testing",
  "Evaluators": {
    "F1Score": {
        "Id": "evaluator_id"
        }
  },
  "status": "Running",
  "id": "f418646d-1745-4606-acf5-f1b5dbd89097",
  "tags" : {},
  "properties": {
    "OutputAssetUri": "<asset url>" // No formal contract for Ignite
  }
}
```

#### Online Evaluation
Results are written back as spans to App Insights traces.

#### Long term goal : [**Still under discussion internally, out of scope for Ignite*]
Long term goal is to have a result API to retrieve evaluation results. API would be `/evaluations/{id}/results`

## Schedule as part of evaluation definition

Pros
- One REST API to create both

Cons
- Evaluation with and without definition will have different respone type, former will return a schedule and latter will return an Evaluation.
- No easy way to get all evaluations generated by schedule.

## Schedule as seprate entity

Pros
- Can we resued for not just evaluation in future.
- Makes the concepts easy to understand.

Cons
- No public ervice backing it right now.
- No funding to build it for Unified SDK.
- Puts evaluation at risk for Ignite.



