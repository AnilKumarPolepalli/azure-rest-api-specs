#!/usr/bin/env python3
"""
TypeSpec Customization Assessment - Final Report Generator

This script creates a comprehensive assessment tool that can be used to evaluate
TypeSpec customization patterns in any Azure REST API specs repository.
"""

import json
import os
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import argparse

class TypeSpecCustomizationAssessment:
    """
    A comprehensive tool to assess TypeSpec customization patterns in Azure REST API specs.
    
    This tool analyzes TypeSpec projects to determine:
    1. Which projects are completely autogenerated vs customized
    2. Common customization patterns
    3. Areas where conversion tooling can be improved
    """
    
    def __init__(self, repo_root: str, analysis_period_months: int = 6):
        self.repo_root = Path(repo_root)
        self.specification_dir = self.repo_root / "specification"
        self.analysis_period = timedelta(days=analysis_period_months * 30)
        self.cutoff_date = datetime.now() - self.analysis_period
        
        # Customization scoring weights
        self.scoring_weights = {
            "client_customization": 1,
            "additional_file": 5,
            "suppressions": 10,
            "large_main_file": 5
        }
        
        # Classification thresholds
        self.classification_thresholds = {
            "autogenerated": 0,
            "lightly_customized": 10,
            "max_commits_light": 3
        }
    
    def find_typespec_projects(self) -> List[Path]:
        """Find all TypeSpec projects in the specification directory."""
        projects = []
        for tspconfig in self.specification_dir.rglob("tspconfig.yaml"):
            # Skip test fixtures and generated test files
            path_str = str(tspconfig)
            if not any(skip in path_str for skip in ["test", "fixture", "generated"]):
                projects.append(tspconfig.parent)
        return projects
    
    def get_project_creation_date(self, project_path: Path) -> Optional[datetime]:
        """Get the creation date of a TypeSpec project."""
        try:
            result = subprocess.run([
                "git", "log", "--follow", "--format=%ci", "--", str(project_path / "tspconfig.yaml")
            ], cwd=self.repo_root, capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout.strip():
                dates = result.stdout.strip().split('\n')
                if dates:
                    return datetime.strptime(dates[-1][:19], "%Y-%m-%d %H:%M:%S")
        except Exception:
            pass
        return None
    
    def analyze_project_customizations(self, project_path: Path) -> Dict:
        """Analyze customization patterns in a TypeSpec project."""
        analysis = {
            "project_path": str(project_path.relative_to(self.repo_root)),
            "has_client_tsp": False,
            "client_tsp_lines": 0,
            "client_tsp_customizations": 0,
            "tsp_files": [],
            "total_tsp_files": 0,
            "main_tsp_lines": 0,
            "additional_tsp_files": 0,
            "has_custom_models": False,
            "has_suppressions": False,
            "customization_score": 0,
            "customization_details": []
        }
        
        # Analyze .tsp files
        tsp_files = list(project_path.glob("*.tsp"))
        analysis["tsp_files"] = [f.name for f in tsp_files]
        analysis["total_tsp_files"] = len(tsp_files)
        
        # Analyze client.tsp
        client_tsp = project_path / "client.tsp"
        if client_tsp.exists():
            analysis["has_client_tsp"] = True
            try:
                with open(client_tsp, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    analysis["client_tsp_lines"] = len(lines)
                    
                    # Count customizations (lines starting with @@)
                    customizations = sum(1 for line in lines if line.strip().startswith('@@'))
                    analysis["client_tsp_customizations"] = customizations
                    
                    if customizations > 0:
                        analysis["customization_details"].append(
                            f"Client.tsp has {customizations} customizations"
                        )
            except Exception:
                pass
        
        # Analyze main.tsp
        main_tsp = project_path / "main.tsp"
        if main_tsp.exists():
            try:
                with open(main_tsp, 'r', encoding='utf-8') as f:
                    content = f.read()
                    analysis["main_tsp_lines"] = len(content.split('\n'))
                    
                    if '#suppress' in content:
                        analysis["has_suppressions"] = True
                        analysis["customization_details"].append("Has suppressions in main.tsp")
            except Exception:
                pass
        
        # Count additional .tsp files
        expected_files = {"main.tsp", "client.tsp"}
        additional_files = [f for f in tsp_files if f.name not in expected_files]
        analysis["additional_tsp_files"] = len(additional_files)
        
        if additional_files:
            analysis["has_custom_models"] = True
            analysis["customization_details"].append(
                f"Has {len(additional_files)} additional model files"
            )
        
        # Calculate customization score
        score = 0
        
        # Client customizations (capped at 20 points)
        if analysis["client_tsp_customizations"] > 0:
            client_score = min(analysis["client_tsp_customizations"], 20)
            score += client_score
        
        # Additional files
        if analysis["additional_tsp_files"] > 0:
            file_score = analysis["additional_tsp_files"] * self.scoring_weights["additional_file"]
            score += file_score
        
        # Suppressions
        if analysis["has_suppressions"]:
            score += self.scoring_weights["suppressions"]
        
        # Large main.tsp file
        if analysis["main_tsp_lines"] > 100:
            score += self.scoring_weights["large_main_file"]
            analysis["customization_details"].append("Large main.tsp file (>100 lines)")
        
        analysis["customization_score"] = score
        return analysis
    
    def get_git_activity(self, project_path: Path) -> Dict:
        """Get git activity for a TypeSpec project."""
        try:
            result = subprocess.run([
                "git", "log", "--oneline", f"--since={self.analysis_period.days} days ago", 
                "--", str(project_path)
            ], cwd=self.repo_root, capture_output=True, text=True)
            
            commits = []
            if result.returncode == 0:
                commits = result.stdout.strip().split('\n') if result.stdout.strip() else []
            
            return {
                "commit_count": len(commits),
                "has_recent_activity": len(commits) > 1
            }
        except Exception:
            return {"commit_count": 0, "has_recent_activity": False}
    
    def classify_project(self, analysis: Dict, git_activity: Dict) -> str:
        """Classify a project based on customization level."""
        score = analysis["customization_score"]
        commit_count = git_activity["commit_count"]
        
        if score == 0 and not git_activity["has_recent_activity"]:
            return "autogenerated"
        elif score <= self.classification_thresholds["lightly_customized"] and \
             commit_count <= self.classification_thresholds["max_commits_light"]:
            return "lightly_customized"
        else:
            return "heavily_customized"
    
    def run_assessment(self) -> Dict:
        """Run the complete assessment and return results."""
        print("TypeSpec Customization Assessment")
        print("=" * 50)
        print(f"Repository: {self.repo_root}")
        print(f"Analysis period: Last {self.analysis_period.days} days")
        print()
        
        # Find all TypeSpec projects
        projects = self.find_typespec_projects()
        print(f"Found {len(projects)} TypeSpec projects")
        
        # Filter projects by creation date
        recent_projects = []
        for project in projects:
            creation_date = self.get_project_creation_date(project)
            if creation_date and creation_date >= self.cutoff_date:
                recent_projects.append(project)
        
        print(f"Projects created in analysis period: {len(recent_projects)}")
        print()
        
        # Analyze each project
        results = []
        for i, project in enumerate(recent_projects, 1):
            print(f"Analyzing {i}/{len(recent_projects)}: {project.name}")
            
            analysis = self.analyze_project_customizations(project)
            git_activity = self.get_git_activity(project)
            classification = self.classify_project(analysis, git_activity)
            
            result = {
                **analysis,
                "git_activity": git_activity,
                "classification": classification
            }
            results.append(result)
        
        # Generate summary report
        report = self.generate_summary_report(results)
        
        return {
            "metadata": {
                "total_projects_found": len(projects),
                "projects_analyzed": len(results),
                "analysis_period_days": self.analysis_period.days,
                "generated_at": datetime.now().isoformat()
            },
            "report": report,
            "detailed_results": results
        }
    
    def generate_summary_report(self, results: List[Dict]) -> Dict:
        """Generate a comprehensive summary report."""
        if not results:
            return {"error": "No projects to analyze"}
        
        total_projects = len(results)
        
        # Classification counts
        classifications = {}
        for result in results:
            classification = result["classification"]
            classifications[classification] = classifications.get(classification, 0) + 1
        
        # Detailed statistics
        stats = {
            "projects_with_client_tsp": sum(1 for r in results if r["has_client_tsp"]),
            "projects_with_custom_models": sum(1 for r in results if r["has_custom_models"]),
            "projects_with_suppressions": sum(1 for r in results if r["has_suppressions"]),
            "average_customization_score": sum(r["customization_score"] for r in results) / total_projects,
            "average_files_per_project": sum(r["total_tsp_files"] for r in results) / total_projects,
            "projects_with_recent_activity": sum(1 for r in results if r["git_activity"]["has_recent_activity"])
        }
        
        # Client.tsp analysis
        client_projects = [r for r in results if r["has_client_tsp"]]
        if client_projects:
            stats["average_client_customizations"] = sum(
                r["client_tsp_customizations"] for r in client_projects
            ) / len(client_projects)
        
        # Percentages
        percentages = {}
        for classification, count in classifications.items():
            percentages[classification] = round((count / total_projects) * 100, 1)
        
        return {
            "total_projects": total_projects,
            "classifications": classifications,
            "percentages": percentages,
            "detailed_statistics": stats
        }
    
    def print_report(self, assessment_results: Dict):
        """Print a formatted report of the assessment results."""
        report = assessment_results["report"]
        metadata = assessment_results["metadata"]
        
        print("\n" + "=" * 60)
        print("TYPESPEC CUSTOMIZATION ASSESSMENT RESULTS")
        print("=" * 60)
        print(f"Generated: {metadata['generated_at'][:19]}")
        print(f"Analysis Period: {metadata['analysis_period_days']} days")
        print(f"Total Projects Found: {metadata['total_projects_found']}")
        print(f"Projects Analyzed: {metadata['projects_analyzed']}")
        print()
        
        if report["total_projects"] == 0:
            print("No projects found in the analysis period.")
            return
        
        # Classification summary
        print("CUSTOMIZATION LEVEL DISTRIBUTION")
        print("-" * 40)
        for classification, count in report["classifications"].items():
            percentage = report["percentages"][classification]
            label = classification.replace("_", " ").title()
            print(f"{label:20}: {count:3d} projects ({percentage:5.1f}%)")
        
        # Key statistics
        print("\nKEY STATISTICS")
        print("-" * 40)
        stats = report["detailed_statistics"]
        print(f"Projects with client.tsp: {stats['projects_with_client_tsp']} ({stats['projects_with_client_tsp']/report['total_projects']*100:.1f}%)")
        print(f"Projects with custom models: {stats['projects_with_custom_models']} ({stats['projects_with_custom_models']/report['total_projects']*100:.1f}%)")
        print(f"Projects with suppressions: {stats['projects_with_suppressions']} ({stats['projects_with_suppressions']/report['total_projects']*100:.1f}%)")
        print(f"Average customization score: {stats['average_customization_score']:.1f}")
        print(f"Average files per project: {stats['average_files_per_project']:.1f}")
        
        if "average_client_customizations" in stats:
            print(f"Average client customizations: {stats['average_client_customizations']:.1f}")
        
        # Conclusion
        autogen_percent = report["percentages"].get("autogenerated", 0)
        customized_percent = 100 - autogen_percent
        
        print("\nCONCLUSION")
        print("-" * 40)
        print(f"Only {autogen_percent:.1f}% of TypeSpec projects remain completely autogenerated.")
        print(f"{customized_percent:.1f}% of projects required customization after conversion.")
        print(f"This indicates that significant manual effort is typically required")
        print(f"when converting from Swagger to TypeSpec.")

def main():
    parser = argparse.ArgumentParser(description="Assess TypeSpec customization patterns")
    parser.add_argument("--repo-root", default="/home/runner/work/azure-rest-api-specs/azure-rest-api-specs",
                       help="Root directory of the azure-rest-api-specs repository")
    parser.add_argument("--months", type=int, default=6,
                       help="Number of months to analyze (default: 6)")
    parser.add_argument("--output", help="Output file for detailed JSON results")
    
    args = parser.parse_args()
    
    # Run the assessment
    assessment = TypeSpecCustomizationAssessment(args.repo_root, args.months)
    results = assessment.run_assessment()
    
    # Print the report
    assessment.print_report(results)
    
    # Save detailed results if requested
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nDetailed results saved to: {args.output}")

if __name__ == "__main__":
    main()